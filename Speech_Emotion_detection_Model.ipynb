{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["# !pip install --upgrade tensorflow keras"],"metadata":{"id":"3zrs8chFDfqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from sklearn import __version__ as sklearn_version\n","\n","\n","# from sklearn.utils import all_estimators\n","# from sklearn.base import ClassifierMixin\n","# from sklearn.exceptions import NotFittedError\n","\n","# import numpy as np\n","\n","# from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n","# from sklearn.base import BaseEstimator, ClassifierMixin\n","# from sklearn.utils.multiclass import unique_labels\n","# from sklearn.utils.validation import check_is_fitted\n","# from sklearn.utils.multiclass import check_classification_targets\n","# from sklearn.metrics import euclidean_distances\n","# from sklearn.preprocessing import LabelEncoder\n","# from sklearn.utils.extmath import safe_sparse_dot\n","\n","# from keras.wrappers.scikit_learn import BaseWrapper\n","# from keras.wrappers.scikit_learn import KerasClassifier\n"],"metadata":{"id":"0RHuy1XG8FlT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import librosa\n","import librosa.display\n","from IPython.display import Audio\n","import warnings\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import RandomizedSearchCV\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","from keras.callbacks import ModelCheckpoint\n","from sklearn.model_selection import GridSearchCV\n","\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"dIUtFkp__fqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)  # forcibly remounting for clarity\n","\n","# dataset_path = \"/content/drive/My Drive/Datasets/TESS\""],"metadata":{"id":"_tIrjhr7_exR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_path = 'https://drive.google.com/drive/folders/17Oxc4Pbsg9728TbjE58F-nMXcpayOFdK'\n","paths = []\n","labels = []\n","for dirname, _, filenames in os.walk(dataset_path):\n","    for filename in filenames:\n","        paths.append(os.path.join(dirname, filename))\n","        label = filename.split('_')[-1]\n","        label = label.split('.')[0]\n","        labels.append(label.lower())\n","    if len(paths) == 2800:\n","        break\n","print('Dataset is Loaded')"],"metadata":{"id":"--n1Laz7_68W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(paths)"],"metadata":{"id":"afK8i0v6vgNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["paths[:5]"],"metadata":{"id":"H_MSfwmZw-VT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels[:5]"],"metadata":{"id":"U2wBHI1IxG8J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Create a dataframe\n","df = pd.DataFrame()\n","df['speech'] = paths\n","df['label'] = labels\n","df.head()"],"metadata":{"id":"FIvgtGPCxSfo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['label'].value_counts()"],"metadata":{"id":"x3DJdFHdxbho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.countplot(data=df, x='label')"],"metadata":{"id":"PbbsoodTxfl2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"in8qOhWD5I73"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def waveplot(data, sr, emotion):\n","    plt.figure(figsize=(10,4))\n","    plt.title(emotion, size=20)\n","    librosa.display.waveshow(data, sr=sr)\n","    plt.show()\n","\n","def spectogram(data, sr, emotion):\n","    x = librosa.stft(data)\n","    xdb = librosa.amplitude_to_db(abs(x))\n","    plt.figure(figsize=(11,4))\n","    plt.title(emotion, size=20)\n","    librosa.display.specshow(xdb, sr=sr, x_axis='time', y_axis='hz')\n","    plt.colorbar()"],"metadata":{"id":"VDzxcQcSykb5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion = 'fear'\n","path = np.array(df['speech'][df['label']==emotion])[0]\n","data, sampling_rate = librosa.load(path)\n","waveplot(data, sampling_rate, emotion)\n","spectogram(data, sampling_rate, emotion)\n","Audio(path)"],"metadata":{"id":"ldj5lQ1lyuBZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion = 'angry'\n","path = np.array(df['speech'][df['label']==emotion])[1]\n","data, sampling_rate = librosa.load(path)\n","waveplot(data, sampling_rate, emotion)\n","spectogram(data, sampling_rate, emotion)\n","Audio(path)"],"metadata":{"id":"kWIn7vOZy9ex"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion = 'disgust'\n","path = np.array(df['speech'][df['label']==emotion])[0]\n","data, sampling_rate = librosa.load(path)\n","waveplot(data, sampling_rate, emotion)\n","spectogram(data, sampling_rate, emotion)\n","Audio(path)"],"metadata":{"id":"Soi9_jiezCaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion = 'neutral'\n","path = np.array(df['speech'][df['label']==emotion])[0]\n","data, sampling_rate = librosa.load(path)\n","waveplot(data, sampling_rate, emotion)\n","spectogram(data, sampling_rate, emotion)\n","Audio(path)"],"metadata":{"id":"-HdYo6MzzKJa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion = 'sad'\n","path = np.array(df['speech'][df['label']==emotion])[0]\n","data, sampling_rate = librosa.load(path)\n","waveplot(data, sampling_rate, emotion)\n","spectogram(data, sampling_rate, emotion)\n","Audio(path)"],"metadata":{"id":"3vHM6sQyzSEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion = 'ps'\n","path = np.array(df['speech'][df['label']==emotion])[0]\n","data, sampling_rate = librosa.load(path)\n","waveplot(data, sampling_rate, emotion)\n","spectogram(data, sampling_rate, emotion)\n","Audio(path)"],"metadata":{"id":"4l7een7HzaUS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emotion = 'happy'\n","path = np.array(df['speech'][df['label']==emotion])[0]\n","data, sampling_rate = librosa.load(path)\n","waveplot(data, sampling_rate, emotion)\n","spectogram(data, sampling_rate, emotion)\n","Audio(path)"],"metadata":{"id":"5JryKN4Wzhld"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_mfcc(filename):\n","    y, sr = librosa.load(filename, duration=3, offset=0.5)\n","    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n","    return mfcc"],"metadata":{"id":"Fuu9uQBazpI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extract_mfcc(df['speech'][0])"],"metadata":{"id":"nyj36_SyzzO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_mfcc = df['speech'].apply(lambda x: extract_mfcc(x))"],"metadata":{"id":"SNIkw6-tz2GQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_mfcc"],"metadata":{"id":"PW4HWvhWz9WY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = [x for x in X_mfcc]\n","X = np.array(X)\n","X.shape"],"metadata":{"id":"0oOn3qC50s8w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## input split\n","X = np.expand_dims(X, -1)\n","X.shape"],"metadata":{"id":"j8dEKz7y0uIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","enc = OneHotEncoder()\n","y = enc.fit_transform(df[['label']])\n"],"metadata":{"id":"r3fDZDn902b_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y = y.toarray()"],"metadata":{"id":"jHBuyFYC0_xg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"id":"0qJnISAl1Bin"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the encoder object\n","import pickle\n","\n","encoder_path = '/content/drive/MyDrive/Datasets/label_encoder.pkl'  # Define the path to save the encoder file\n","with open(encoder_path, 'wb') as f:\n","    pickle.dump(enc, f)"],"metadata":{"id":"4sNmcVBM0m_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from keras.models import Sequential\n","# from keras.layers import Dense, LSTM, Dropout\n","# from keras.callbacks import ModelCheckpoint\n","\n","# model = Sequential([\n","#     LSTM(256, return_sequences=False, input_shape=(40,1)),\n","#     Dropout(0.2),\n","#     Dense(128, activation='relu'),\n","#     Dropout(0.2),\n","#     Dense(64, activation='relu'),\n","#     Dropout(0.2),\n","#     Dense(7, activation='softmax')\n","# ])\n","\n","# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","# model.summary()\n","\n","# # Create a checkpoint to save the best model based on validation accuracy\n","# checkpoint = ModelCheckpoint('/content/drive/MyDrive/Datasets/best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n","\n","# # Train the model with checkpoint callback\n","# history = model.fit(X, y, validation_split=0.2, epochs=70, batch_size=64, callbacks=[checkpoint])"],"metadata":{"id":"K4zemtWa1WWB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from tensorflow import keras\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import OneHotEncoder\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from keras.callbacks import ModelCheckpoint\n","\n","# Define a function to create the model\n","def create_model(optimizer='adam', dropout_rate=0.2):\n","    model = Sequential([\n","        LSTM(256, return_sequences=False, input_shape=(40,1)),\n","        Dropout(dropout_rate),\n","        Dense(128, activation='relu'),\n","        Dropout(dropout_rate),\n","        Dense(64, activation='relu'),\n","        Dropout(dropout_rate),\n","        Dense(7, activation='softmax')\n","    ])\n","    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","    return model\n","\n","# Create a KerasClassifier wrapper for use in GridSearchCV\n","model = KerasClassifier(build_fn=create_model, verbose=0)\n","\n","# Define the grid of hyperparameters to search\n","param_grid = {\n","    'batch_size': [32, 64, 128],\n","    'epochs': [50, 100, 150],\n","    'optimizer': ['adam', 'rmsprop'],\n","    'dropout_rate': [0.2, 0.3, 0.4]\n","}\n","\n","# Perform grid search with cross-validation\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n","try:\n","    grid_result = grid_search.fit(X, y)\n","except Exception as e:\n","    print(\"Error occurred during grid search fitting:\", e)\n","\n","\n","# Print the best parameters and accuracy\n","print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n","means = grid_result.cv_results_['mean_test_score']\n","stds = grid_result.cv_results_['std_test_score']\n","params = grid_result.cv_results_['params']\n","for mean, stdev, param in zip(means, stds, params):\n","    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n","\n","# Save the best model\n","best_model = grid_result.best_estimator_.model\n","best_model.save('/content/drive/MyDrive/Datasets/best_model.h5')\n","\n","# Train the best model\n","history = best_model.fit(X, y, validation_split=0.2, epochs=grid_result.best_params_['epochs'], batch_size=grid_result.best_params_['batch_size'])\n","\n","# Print information about the saved model\n","print(\"Best model training completed.\")\n","print(\"Accuracy:\", history.history['accuracy'])\n","print(\"Validation Accuracy:\", history.history['val_accuracy'])\n","print(\"Loss:\", history.history['loss'])\n","print(\"Validation Loss:\", history.history['val_loss'])\n","print(\"Label encoder saved as label_encoder.pkl.\")\n"],"metadata":{"id":"Oz1HOIPq1RBz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import librosa\n","from keras.models import load_model\n","import pickle\n","\n","# Load the saved model\n","saved_model_path = '/content/drive/MyDrive/Datasets/best_model.h5'\n","loaded_model = load_model(saved_model_path)\n","\n","# Load the encoder\n","encoder_path = '/content/drive/MyDrive/Datasets/label_encoder.pkl'\n","with open(encoder_path, 'rb') as f:\n","    label_encoder = pickle.load(f)\n","\n","# Define a function to extract MFCC features from an audio file\n","def extract_mfcc(filename):\n","    y, sr = librosa.load(filename, duration=3, offset=0.5)\n","    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n","    return mfcc\n","\n","# Define a function to predict emotion from an audio file\n","def predict_emotion(audio_file):\n","    # Extract MFCC features from the audio file\n","    mfcc_features = extract_mfcc(audio_file)\n","    # Reshape the features for model input\n","    mfcc_features = np.expand_dims(mfcc_features, axis=0)\n","    mfcc_features = np.expand_dims(mfcc_features, axis=-1)\n","    # Predict the emotion using the loaded model\n","    predicted_probabilities = loaded_model.predict(mfcc_features)\n","    # Get the predicted emotion label index\n","    predicted_emotion_index = np.argmax(predicted_probabilities)\n","    # Decode the predicted emotion label\n","    predicted_emotion_label = label_encoder.inverse_transform([[predicted_emotion_index]])[0][0]\n","    return predicted_emotion_label\n","\n","# Define the path to the audio file you want to test\n","audio_file_path = '/content/drive/MyDrive/Datasets/TESS Toronto emotional speech set data/YAF_sad/YAF_youth_sad.wav'\n","\n","# Predict the emotion from the audio file\n","predicted_emotion = predict_emotion(audio_file_path)\n","\n","print(\"Predicted Emotion:\", predicted_emotion)\n"],"metadata":{"id":"klmrBKHH5dVQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !pip install tensorflow"],"metadata":{"id":"1GgnJXCGAof9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from tensorflow import keras\n","\n","# # Load your saved model\n","# model = keras.models.load_model(\"/content/drive/MyDrive/Datasets/best_model.h5\")\n","\n","# # Print model summary\n","# print(\"Model Summary:\")\n","# model.summary()\n","\n","# # Print individual layer details\n","# print(\"\\nLayer Details:\")\n","# for i, layer in enumerate(model.layers):\n","#     print(f\"Layer {i+1}:\")\n","#     print(f\"- Name: {layer.name}\")\n","#     print(f\"- Type: {layer.__class__.__name__}\")\n","#     print(f\"- Output shape: {layer.output_shape}\")\n","#     print(f\"- Input shape: {layer.input_shape}\\n\")\n","# # Access the last layer (output layer) using indexing\n","# output_layer = model.layers[-1]\n","\n","# # Check for expected layer structure and activation\n","# if output_layer.name == \"dense_8\" and output_layer.activation == \"softmax\":\n","#     # Assuming 7 output units corresponding to 7 emotions\n","#     labels = [\"anger\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n","\n","#     # Check if output units have meaningful names (optional)\n","#     try:\n","#         output_names = [model.output_layer.get_weights()[1][i] for i in range(len(labels))]\n","#         print(\"\\nPotential Label Mapping (if output units have names):\")\n","#         for i, name in enumerate(output_names):\n","#             if name:\n","#                 print(f\"- Unit {i+1}: {name}\")\n","#             else:\n","#                 print(f\"- Unit {i+1}: No name assigned\")\n","#     except Exception as e:\n","#         print(f\"Error checking output unit names: {e}\")\n","# else:\n","#     print(\"Output layer configuration might not align with label mapping assumptions. Adjust the code based on your model's structure.\")\n"],"metadata":{"id":"heff7g0Deocm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Define function to extract MFCC features\n","# def extract_mfcc(filename):\n","#   y, sr = librosa.load(filename, duration=3, offset=0.5)\n","#   mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n","#   return mfcc"],"metadata":{"id":"PgsxVwDS1k4Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import tensorflow as tf\n","# # Load the saved model\n","# model = tf.keras.models.load_model('/content/drive/MyDrive/Datasets/best_model.h5')  # Replace with your actual path\n"],"metadata":{"id":"iI6-L0eG_iOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Function for prediction\n","# def predict_emotion(audio_file):\n","#   # Extract MFCC features\n","#   mfcc_features = extract_mfcc(audio_file)\n","#   mfcc_features = np.expand_dims(mfcc_features, axis=0)\n","\n","#   # Make prediction\n","#   prediction = model.predict(mfcc_features)\n","#   predicted_emotion = np.argmax(prediction)\n","\n","#   # Map prediction to emotion label\n","#   # Assuming you have a label mapping defined elsewhere\n","#   emotion_labels = ['anger', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n","#   predicted_emotion = emotion_labels[predicted_emotion]\n","\n","#   return predicted_emotion"],"metadata":{"id":"O92LdcLx_jWd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Example usage\n","# audio_file_path = '/content/drive/MyDrive/Datasets/TESS Toronto emotional speech set data/YAF_sad/YAF_youth_sad.wav'  # Replace with your actual path\n","# predicted_emotion = predict_emotion(audio_file_path)\n","\n","# print(f\"Predicted emotion: {predicted_emotion}\")"],"metadata":{"id":"7JFQlYBg_vcE"},"execution_count":null,"outputs":[]}]}